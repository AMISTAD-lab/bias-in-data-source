{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import choices\n",
    "import scipy.stats as st\n",
    "import plotly.io\n",
    "import plotly.graph_objects as go\n",
    "from hypothesis_test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11742, 47)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "df = pd.read_csv(r'Datasets/compas-scores.csv')\n",
    "df = df[df['decile_score'] != -1]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for experiments\n",
    "def group_decile_scores(score_list, num_groups):\n",
    "    \"\"\"\n",
    "    This function groups scores together based on a given number of groups\n",
    "    (num_groups). This would be the equivalent of sorting scores into\n",
    "    different tiers (very low, low, etc.) where the number of tiers is\n",
    "    num_groups. The function also returns a distribution of those tiers\n",
    "    within the given score_list.\n",
    "    \"\"\"\n",
    "    bound_increment = 10/num_groups\n",
    "    group_list = []\n",
    "    last_lower_bound = 0\n",
    "    for i in range(num_groups):\n",
    "        upper_bound = last_lower_bound + bound_increment\n",
    "        group_list.append([last_lower_bound, upper_bound])\n",
    "        last_lower_bound = upper_bound\n",
    "    grouped_score_list = []\n",
    "    for score in score_list:\n",
    "        for group in group_list:\n",
    "            if group[0] <= score and score <= group[1]:\n",
    "                grouped_score_list.append(group_list.index(group))\n",
    "                break\n",
    "    grouped_score_distribution = [grouped_score_list.count(i)/len(grouped_score_list) for i in range(num_groups)]\n",
    "    return (grouped_score_list, grouped_score_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.36 s ± 25.7 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n",
      "1.41 s ± 9.57 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n",
      "2.05 s ± 24.8 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n",
      "4.4 s ± 31.1 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n",
      "12.4 s ± 87.2 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n",
      "38.7 s ± 377 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n",
      "2min 5s ± 1.1 s per loop (mean ± std. dev. of 10 runs, 1 loop each)\n",
      "6min 40s ± 18.1 s per loop (mean ± std. dev. of 10 runs, 1 loop each)\n",
      "22min 49s ± 1min 35s per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Setup and Experiments\n",
    "AA_decile_scores = df[df['race'] == 'African-American']['decile_score'].tolist()\n",
    "AA_decile_score_props = [AA_decile_scores.count(i)/len(AA_decile_scores) for i in range(1,11)]\n",
    "possible_scores = list(range(1,11))\n",
    "extrapolated_AA_scores = list(choices(possible_scores, AA_decile_score_props, k=100000))\n",
    "white_decile_scores = df[df['race'] == 'Caucasian']['decile_score'].tolist()\n",
    "\n",
    "alpha = 0.05\n",
    "conf_interval_list = []\n",
    "num_vals = list(range(2,11))\n",
    "\n",
    "for val_count in num_vals:\n",
    "    data = group_decile_scores(extrapolated_AA_scores, val_count)[0]\n",
    "    val_list = list(range(val_count))\n",
    "    hypothesis = group_decile_scores(white_decile_scores, val_count)[1]\n",
    "    time = %timeit -n 1 -r 10 -o hypothesis_test_silent(data, val_list, alpha, hypothesis)\n",
    "    units = 's'\n",
    "    mean = time.average\n",
    "    stdev = time.stdev\n",
    "    if mean >= 60: # Convert from seconds to minutes if necessary\n",
    "        mean /= 60\n",
    "        stdev /= 60\n",
    "        units = 'min'\n",
    "    n = 100000 # Length of extrapolated dataset\n",
    "    conf_interval = st.t.interval(0.95, df=n-1, loc=mean, scale=stdev)\n",
    "    rounded_conf_interval = tuple(round(i, 2) for i in conf_interval)\n",
    "    conf_interval_list.append(str(rounded_conf_interval) + ' ' + units)\n",
    "\n",
    "fig = go.Figure(data=[go.Table(header=dict(values=['Num Labels', 'Run Time 95% CI']),\n",
    "                cells=dict(values=[num_vals, conf_interval_list]))],\n",
    "                layout=go.Layout(title=go.layout.Title(\n",
    "                text=\"Hypothesis Test Run Time by Number of Labels\")))\n",
    "plotly.io.write_image(fig, r\"Results/run_time_decile_score_results.pdf\", format=\"pdf\", engine=\"orca\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
